{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":99552,"databundleVersionId":13762876,"sourceType":"competition"},{"sourceId":12637336,"sourceType":"datasetVersion","datasetId":7981664}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Kaggle: Do NOT install torch/torchvision here!\n!pip install pyradiomics SimpleITK nibabel scikit-learn xgboost lightgbm timm einops\n\nimport os\nimport gc\nimport pickle\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Optional\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport timm\nfrom einops import rearrange\nimport SimpleITK as sitk\nimport nibabel as nib\nfrom PIL import Image\n\nfrom radiomics import featureextractor\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nimport xgboost as xgb\nimport lightgbm as lgb\n\nwarnings.filterwarnings('ignore')\n\n##############################################################\n# MODALITY-SPECIFIC NORMALIZATION\n##############################################################\n\ndef normalize_image(volume: np.ndarray, modality: str) -> np.ndarray:\n    modality = modality.upper().strip()\n    if \"CTA\" in modality or \"CT\" in modality:\n        center, width = 250, 600\n        min_val = center - width // 2\n        max_val = center + width // 2\n        if volume.max() <= 1.0:\n            volume = volume * 500 - 100\n        volume = np.clip(volume, min_val, max_val)\n        volume = (volume - min_val) / float(max_val - min_val)\n        volume = np.clip(volume, 0, 1)\n    elif \"MRA\" in modality or \"MRI\" in modality:\n        mean_val = np.mean(volume)\n        std_val = np.std(volume)\n        if std_val < 1e-6:\n            std_val = 1.0\n        volume = (volume - mean_val) / std_val\n    else:\n        min_val = np.min(volume)\n        max_val = np.max(volume)\n        if max_val - min_val < 1e-6:\n            volume = np.zeros_like(volume)\n        else:\n            volume = (volume - min_val) / (max_val - min_val)\n    return volume.astype(np.float32)\n\n##############################################################\n# CONFIGURATION\n##############################################################\n\nclass Config:\n    PNG_ROOT = \"/kaggle/input/rsna-2025-intracranial-aneurysm-png-224x224/cvt_png\"\n    SEGMENTATION_ROOT = \"/kaggle/input/rsna-intracranial-aneurysm-detection/segmentations\"\n    TRAIN_CSV = \"/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv\"\n    BATCH_SIZE = 4\n    IMG_SIZE = 224\n    SEED = 42\n    N_FOLDS = 5\n    RADIOMICS_FEATURES = True\n    DEEP_FEATURES = True\n    VIT_FEATURES = True\n    ARTERIES = [\n        'Left Infraclinoid Internal Carotid Artery',\n        'Right Infraclinoid Internal Carotid Artery', \n        'Left Supraclinoid Internal Carotid Artery',\n        'Right Supraclinoid Internal Carotid Artery',\n        'Left Anterior Cerebral Artery',\n        'Right Anterior Cerebral Artery',\n        'Anterior Communicating Artery',\n        'Left Middle Cerebral Artery',\n        'Right Middle Cerebral Artery',\n        'Left Posterior Communicating Artery',\n        'Right Posterior Communicating Artery',\n        'Basilar Tip',\n        'Other Posterior Circulation'\n    ]\n\n##############################################################\n# DATASET\n##############################################################\n\nclass AneurysmDataset(Dataset):\n    def __init__(self, series_data: pd.DataFrame, config: Config, mode: str = 'train', transform=None):\n        self.series_data = series_data\n        self.config = config\n        self.mode = mode\n        self.transform = transform\n    def __len__(self):\n        return len(self.series_data)\n    def __getitem__(self, idx):\n        row = self.series_data.iloc[idx]\n        series_id = row['SeriesInstanceUID']\n        modality = row.get('Modality', 'MRA')\n        png_series_path = self._find_png_series(series_id)\n        if png_series_path is None:\n            return {\n                'volume': np.zeros((1, self.config.IMG_SIZE, self.config.IMG_SIZE), dtype=np.float32),\n                'mask': None,\n                'series_id': series_id,\n                'modality': modality,\n                'labels': np.zeros(14, dtype=np.float32) if self.mode == 'train' else None\n            }\n        volume = self._load_png_series(png_series_path, modality)\n        mask = self._load_segmentation_mask(series_id)\n        if self.transform:\n            volume = self.transform(volume)\n        return {\n            'volume': volume,\n            'mask': mask,\n            'series_id': series_id,\n            'modality': modality,\n            'labels': self._get_labels(row) if self.mode == 'train' else None\n        }\n    def _find_png_series(self, series_id: str) -> Optional[Path]:\n        for artery_folder in Path(self.config.PNG_ROOT).iterdir():\n            if artery_folder.is_dir():\n                series_folder = artery_folder / series_id\n                if series_folder.exists():\n                    return series_folder\n        return None\n    def _load_png_series(self, series_path: Path, modality: str) -> np.ndarray:\n        png_files = sorted([f for f in series_path.glob('*.png')])\n        if not png_files:\n            return np.zeros((1, self.config.IMG_SIZE, self.config.IMG_SIZE))\n        slices = []\n        for png_file in png_files:\n            img = Image.open(png_file).convert('L')\n            img_array = np.array(img, dtype=np.float32)\n            if img_array.max() > 1.0:\n                img_array = img_array / 255.0\n            slices.append(img_array)\n        volume = np.stack(slices, axis=0)\n        volume = normalize_image(volume, modality)\n        return volume\n    def _load_segmentation_mask(self, series_id: str) -> Optional[np.ndarray]:\n        mask_path = Path(self.config.SEGMENTATION_ROOT) / f\"{series_id}.nii\"\n        if mask_path.exists():\n            try:\n                mask_nii = nib.load(str(mask_path))\n                mask = mask_nii.get_fdata().astype(np.uint8)\n                return mask\n            except Exception as e:\n                print(f\"Error loading mask for {series_id}: {e}\")\n        return None\n    def _get_labels(self, row: pd.Series) -> np.ndarray:\n        labels = []\n        labels.append(1 if row.get('Aneurysm Present', 0) == 1 else 0)\n        for artery in self.config.ARTERIES:\n            artery_short = artery.replace(' ', '').replace('Internal', 'Infra')[:15] if len(artery) > 15 else artery\n            label_val = 0\n            for col in row.index:\n                if artery in col or artery_short in col:\n                    label_val = 1 if row[col] == 1 else 0\n                    break\n            labels.append(label_val)\n        return np.array(labels, dtype=np.float32)\n\n##############################################################\n# 3D UNet, MedicalViT, RadiomicsExtractor, FeaturePipeline, and EnsembleModel (as in your previous code)\n# Copy the same implementations as above, or ask if you want them pasted here in full as well (they are long).\n##############################################################\n\n# Main pipeline and scoring functions follow as before.\n\n\n\n\n# ======================================================================\n# 3D U-NET MODEL FOR DEEP FEATURE EXTRACTION\n# ======================================================================\nclass DoubleConv(nn.Module):\n    \"\"\"Double convolution block for U-Net\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm3d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm3d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass UNet3D(nn.Module):\n    \"\"\"3D U-Net for feature extraction and segmentation\"\"\"\n\n    def __init__(self, n_channels=1, n_classes=14, feature_dim=512):\n        super().__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n\n        # Encoder\n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = nn.Sequential(nn.MaxPool3d(2), DoubleConv(64, 128))\n        self.down2 = nn.Sequential(nn.MaxPool3d(2), DoubleConv(128, 256))\n        self.down3 = nn.Sequential(nn.MaxPool3d(2), DoubleConv(256, 512))\n\n        # Feature extraction\n        self.feature_pool = nn.AdaptiveAvgPool3d(1)\n        self.feature_fc = nn.Linear(512, feature_dim)\n\n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(feature_dim, n_classes),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        # Add channel dimension if needed\n        if len(x.shape) == 4:\n            x = x.unsqueeze(1)  # [B, 1, D, H, W]\n\n        # Encoder\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n\n        # Feature extraction\n        features = self.feature_pool(x4).squeeze(-1).squeeze(-1).squeeze(-1)\n        features = self.feature_fc(features)\n\n        # Classification\n        outputs = self.classifier(features)\n\n        return outputs, features\n\n# ======================================================================\n# VISION TRANSFORMER FOR MEDICAL IMAGING\n# ======================================================================\nclass MedicalViT(nn.Module):\n    \"\"\"Vision Transformer adapted for 3D medical volumes\"\"\"\n\n    def __init__(self, \n                 image_size=224,\n                 patch_size=16,\n                 num_slices=32,\n                 num_classes=14,\n                 dim=768,\n                 depth=12,\n                 heads=12,\n                 mlp_dim=3072,\n                 dropout=0.1):\n        super().__init__()\n\n        self.image_size = image_size\n        self.patch_size = patch_size\n        self.num_slices = num_slices\n        self.num_classes = num_classes\n\n        # Load pretrained 2D ViT and adapt for 3D\n        self.vit_2d = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=0)\n\n        # 3D to 2D adapter - process each slice\n        self.slice_processor = nn.Identity()\n\n        # Feature aggregation across slices\n        self.slice_attention = nn.MultiheadAttention(dim, heads, dropout=dropout)\n        self.slice_norm = nn.LayerNorm(dim)\n\n        # Final classifier\n        self.classifier = nn.Sequential(\n            nn.LayerNorm(dim),\n            nn.Dropout(dropout),\n            nn.Linear(dim, num_classes),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        # x shape: [B, D, H, W] or [B, 1, D, H, W]\n        if len(x.shape) == 5:\n            x = x.squeeze(1)  # Remove channel dim if present\n\n        batch_size, depth, height, width = x.shape\n\n        # Process each slice through 2D ViT\n        slice_features = []\n\n        # Limit number of slices to prevent memory issues\n        max_slices = min(depth, self.num_slices)\n        slice_indices = np.linspace(0, depth-1, max_slices).astype(int)\n\n        for i in slice_indices:\n            # Get slice and add channel dimension\n            slice_img = x[:, i:i+1, :, :]  # [B, 1, H, W]\n\n            # Convert to 3-channel for pretrained model\n            slice_img = slice_img.repeat(1, 3, 1, 1)  # [B, 3, H, W]\n\n            # Extract features using pretrained ViT\n            slice_feat = self.vit_2d(slice_img)  # [B, 768]\n            slice_features.append(slice_feat)\n\n        # Stack slice features\n        slice_features = torch.stack(slice_features, dim=1)  # [B, num_slices, 768]\n\n        # Apply attention across slices\n        slice_features = slice_features.transpose(0, 1)  # [num_slices, B, 768]\n        attended_features, _ = self.slice_attention(slice_features, slice_features, slice_features)\n        attended_features = self.slice_norm(attended_features + slice_features)\n\n        # Global average pooling across slices\n        global_features = attended_features.mean(dim=0)  # [B, 768]\n\n        # Classification\n        outputs = self.classifier(global_features)\n\n        return outputs, global_features\n\n# ======================================================================\n# ENHANCED RADIOMICS EXTRACTOR\n# ======================================================================\nclass RadiomicsExtractor:\n    \"\"\"Extract radiomics features using PyRadiomics with modality awareness\"\"\"\n\n    def __init__(self):\n        # Initialize radiomics extractor\n        self.extractor = featureextractor.RadiomicsFeatureExtractor()\n\n        # Configure settings\n        settings = {\n            'binWidth': 25,\n            'resampledPixelSpacing': None,\n            'interpolator': 'sitkLinear',\n            'verbose': False\n        }\n\n        self.extractor.enableAllImageTypes()\n        self.extractor.enableAllFeatures()\n\n        for key, value in settings.items():\n            self.extractor.settings[key] = value\n\n    def extract_features(self, volume: np.ndarray, mask: np.ndarray = None, modality: str = \"MRA\") -> Dict:\n        \"\"\"Extract radiomics features from volume with modality-specific settings\"\"\"\n\n        # Convert to SimpleITK images\n        volume_sitk = sitk.GetImageFromArray(volume.astype(np.float32))\n\n        if mask is not None:\n            mask_sitk = sitk.GetImageFromArray(mask.astype(np.uint8))\n        else:\n            # Create full volume mask\n            mask_sitk = sitk.GetImageFromArray(np.ones_like(volume).astype(np.uint8))\n\n        # Set spacing (assume isotropic 1mm)\n        volume_sitk.SetSpacing((1.0, 1.0, 1.0))\n        mask_sitk.SetSpacing((1.0, 1.0, 1.0))\n\n        try:\n            # Extract features\n            features = self.extractor.execute(volume_sitk, mask_sitk)\n\n            # Filter out non-feature keys and add modality prefix\n            radiomics_features = {}\n            for key, value in features.items():\n                if key.startswith(('original_', 'wavelet-', 'log-', 'square-', 'squareroot-', 'logarithm-', 'exponential-')):\n                    try:\n                        radiomics_features[f\"{modality}_{key}\"] = float(value)\n                    except (ValueError, TypeError):\n                        continue\n\n            return radiomics_features\n\n        except Exception as e:\n            print(f\"Radiomics extraction failed for {modality}: {e}\")\n            return {}\n\n# ======================================================================\n# ENHANCED FEATURE PIPELINE\n# ======================================================================\nclass FeaturePipeline:\n    \"\"\"Complete feature extraction pipeline with ViT integration\"\"\"\n\n    def __init__(self, config: Config):\n        self.config = config\n        self.deep_model = None\n        self.vit_model = None\n        self.radiomics_extractor = RadiomicsExtractor()\n        self.scaler = StandardScaler()\n        self.feature_selector = SelectKBest(f_classif, k=100)  # Increased for more features\n\n    def load_models(self, deep_model_path: str = None, vit_model_path: str = None):\n        \"\"\"Load or initialize deep learning models\"\"\"\n\n        # Load 3D U-Net\n        if self.config.DEEP_FEATURES:\n            self.deep_model = UNet3D()\n            if deep_model_path and os.path.exists(deep_model_path):\n                self.deep_model.load_state_dict(torch.load(deep_model_path))\n            self.deep_model.eval()\n\n        # Load ViT\n        if self.config.VIT_FEATURES:\n            self.vit_model = MedicalViT()\n            if vit_model_path and os.path.exists(vit_model_path):\n                self.vit_model.load_state_dict(torch.load(vit_model_path))\n            self.vit_model.eval()\n\n    def extract_features(self, dataset: AneurysmDataset) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Extract all features from dataset\"\"\"\n\n        all_features = []\n        all_labels = []\n\n        dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)\n\n        for i, batch in enumerate(dataloader):\n            if batch is None:\n                continue\n\n            volume = batch['volume'][0].numpy()  # Remove batch dimension\n            mask = batch['mask'][0] if batch['mask'][0] is not None else None\n            modality = batch['modality'][0]\n            labels = batch['labels'][0] if batch['labels'][0] is not None else None\n\n            print(f\"Processing sample {i+1}/{len(dataloader)}: {batch['series_id'][0]} ({modality})\")\n\n            # Extract features\n            features = {}\n\n            # Deep features (3D U-Net)\n            if self.config.DEEP_FEATURES and self.deep_model:\n                try:\n                    with torch.no_grad():\n                        volume_tensor = torch.FloatTensor(volume).unsqueeze(0)\n                        _, deep_feats = self.deep_model(volume_tensor)\n                        deep_feats = deep_feats.squeeze().numpy()\n\n                        for j, feat in enumerate(deep_feats):\n                            features[f'{modality}_deep_feature_{j}'] = feat\n                except Exception as e:\n                    print(f\"Deep feature extraction failed: {e}\")\n\n            # ViT features\n            if self.config.VIT_FEATURES and self.vit_model:\n                try:\n                    with torch.no_grad():\n                        volume_tensor = torch.FloatTensor(volume).unsqueeze(0)\n                        _, vit_feats = self.vit_model(volume_tensor)\n                        vit_feats = vit_feats.squeeze().numpy()\n\n                        for j, feat in enumerate(vit_feats):\n                            features[f'{modality}_vit_feature_{j}'] = feat\n                except Exception as e:\n                    print(f\"ViT feature extraction failed: {e}\")\n\n            # Radiomics features\n            if self.config.RADIOMICS_FEATURES:\n                try:\n                    mask_array = mask.numpy() if mask is not None else None\n                    radiomics_feats = self.radiomics_extractor.extract_features(volume, mask_array, modality)\n                    features.update(radiomics_feats)\n                except Exception as e:\n                    print(f\"Radiomics extraction failed: {e}\")\n\n            if features:\n                all_features.append(features)\n                if labels is not None:\n                    all_labels.append(labels.numpy())\n\n            # Memory cleanup\n            if i % 10 == 0:\n                gc.collect()\n\n        # Convert to arrays\n        if all_features:\n            print(f\"Creating feature matrix from {len(all_features)} samples...\")\n            feature_df = pd.DataFrame(all_features).fillna(0)\n            X = feature_df.values\n            y = np.array(all_labels) if all_labels else None\n\n            print(f\"Feature matrix shape: {X.shape}\")\n            return X, y\n\n        return np.array([]), np.array([])\n\n# ======================================================================\n# ENHANCED ENSEMBLE MODEL\n# ======================================================================\nclass EnsembleModel:\n    \"\"\"Stacking ensemble with multiple base models optimized for medical imaging\"\"\"\n\n    def __init__(self, config: Config):\n        self.config = config\n\n        # Base models with medical imaging optimizations\n        self.base_models = {\n            'rf': RandomForestClassifier(\n                n_estimators=200,\n                max_depth=10, \n                min_samples_split=5,\n                random_state=config.SEED,\n                n_jobs=-1\n            ),\n            'xgb': xgb.XGBClassifier(\n                n_estimators=200,\n                max_depth=6,\n                learning_rate=0.1,\n                subsample=0.8,\n                colsample_bytree=0.8,\n                random_state=config.SEED,\n                eval_metric='logloss'\n            ),\n            'lgb': lgb.LGBMClassifier(\n                n_estimators=200,\n                max_depth=6,\n                learning_rate=0.1,\n                feature_fraction=0.8,\n                bagging_fraction=0.8,\n                random_state=config.SEED,\n                verbose=-1\n            )\n        }\n\n        # Meta-learner\n        self.meta_model = LogisticRegression(\n            random_state=config.SEED,\n            max_iter=1000,\n            C=0.1\n        )\n\n        self.is_fitted = False\n\n    def fit(self, X: np.ndarray, y: np.ndarray):\n        \"\"\"Fit ensemble model with improved stacking\"\"\"\n\n        print(\"Training ensemble model with stacking...\")\n\n        # Generate meta-features using cross-validation\n        n_models = len(self.base_models)\n        n_labels = y.shape[1]\n        meta_features = np.zeros((X.shape[0], n_models * n_labels))\n\n        kf = StratifiedKFold(n_splits=self.config.N_FOLDS, shuffle=True, random_state=self.config.SEED)\n\n        for fold, (train_idx, val_idx) in enumerate(kf.split(X, y[:, 0])):  # Stratify on global label\n            print(f\"Processing fold {fold + 1}/{self.config.N_FOLDS}\")\n\n            X_train, X_val = X[train_idx], X[val_idx]\n            y_train, y_val = y[train_idx], y[val_idx]\n\n            for i, (name, model) in enumerate(self.base_models.items()):\n                print(f\"  Training {name}...\")\n\n                # Train base model\n                if hasattr(model, 'fit'):\n                    model.fit(X_train, y_train)\n\n                # Predict on validation set\n                if hasattr(model, 'predict_proba'):\n                    val_pred = model.predict_proba(X_val)\n                else:\n                    val_pred = model.predict(X_val)\n\n                # Store meta-features\n                start_idx = i * n_labels\n                end_idx = (i + 1) * n_labels\n\n                if isinstance(val_pred, list) and len(val_pred) == n_labels:\n                    # Multi-output case (sklearn style)\n                    for j in range(n_labels):\n                        if hasattr(val_pred[j], 'shape') and len(val_pred[j].shape) > 1:\n                            meta_features[val_idx, start_idx + j] = val_pred[j][:, 1]\n                        else:\n                            meta_features[val_idx, start_idx + j] = val_pred[j]\n                else:\n                    # Single output case\n                    if len(val_pred.shape) == 2 and val_pred.shape[1] == n_labels:\n                        meta_features[val_idx, start_idx:end_idx] = val_pred\n                    else:\n                        # Fallback: use predictions as is\n                        meta_features[val_idx, start_idx:start_idx+1] = val_pred.reshape(-1, 1)\n\n        # Train final base models on full dataset\n        print(\"Training final base models...\")\n        for name, model in self.base_models.items():\n            print(f\"  Final training {name}...\")\n            model.fit(X, y)\n\n        # Train meta-learner\n        print(\"Training meta-learner...\")\n        self.meta_model.fit(meta_features, y)\n\n        self.is_fitted = True\n        print(\"Ensemble training completed!\")\n\n    def predict(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"Make predictions using ensemble\"\"\"\n\n        if not self.is_fitted:\n            raise ValueError(\"Model must be fitted before making predictions\")\n\n        # Generate meta-features\n        meta_features = []\n\n        for name, model in self.base_models.items():\n            if hasattr(model, 'predict_proba'):\n                pred = model.predict_proba(X)\n            else:\n                pred = model.predict(X)\n\n            if isinstance(pred, list):\n                # Multi-output case\n                meta_feat = np.column_stack([\n                    p[:, 1] if len(p.shape) > 1 and p.shape[1] > 1 else p.ravel()\n                    for p in pred\n                ])\n            else:\n                # Single output case\n                if len(pred.shape) == 1:\n                    meta_feat = pred.reshape(-1, 1)\n                else:\n                    meta_feat = pred\n\n            meta_features.append(meta_feat)\n\n        meta_X = np.column_stack(meta_features)\n\n        # Final prediction\n        if hasattr(self.meta_model, 'predict_proba'):\n            final_pred = self.meta_model.predict_proba(meta_X)\n            if isinstance(final_pred, list):\n                return np.column_stack([p[:, 1] for p in final_pred])\n            else:\n                return final_pred\n        else:\n            return self.meta_model.predict(meta_X)\n\n# ======================================================================\n# EVALUATION FUNCTIONS\n# ======================================================================\ndef calculate_competition_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n    \"\"\"Calculate weighted competition score\"\"\"\n\n    try:\n        # Global aneurysm AUC (weight = 13)\n        if len(np.unique(y_true[:, 0])) > 1:\n            global_auc = roc_auc_score(y_true[:, 0], y_pred[:, 0])\n        else:\n            global_auc = 0.5\n\n        # Per-artery AUCs (weight = 1 each)\n        artery_aucs = []\n        for i in range(1, min(y_true.shape[1], y_pred.shape[1])):\n            if len(np.unique(y_true[:, i])) > 1:  # Check if both classes present\n                auc = roc_auc_score(y_true[:, i], y_pred[:, i])\n                artery_aucs.append(auc)\n\n        # Weighted score\n        if len(artery_aucs) > 0:\n            total_weight = 13 + len(artery_aucs)\n            weighted_score = (13 * global_auc + sum(artery_aucs)) / total_weight\n        else:\n            weighted_score = global_auc\n\n        return weighted_score\n\n    except Exception as e:\n        print(f\"Error calculating competition score: {e}\")\n        return 0.0\n\n# ======================================================================\n# MAIN PIPELINE\n# ======================================================================\ndef main():\n    \"\"\"Main execution pipeline with enhanced features\"\"\"\n\n    print(\"🔬 Starting Enhanced Multimodal Aneurysm Detection Pipeline...\")\n    print(\"✨ Features: Modality-specific normalization, 3D U-Net, ViT, Advanced ensemble\")\n\n    config = Config()\n\n    # Load training data\n    print(\"📊 Loading training data...\")\n    train_df = pd.read_csv(config.TRAIN_CSV)\n    print(f\"Loaded {len(train_df)} training samples\")\n\n    # Display modality distribution\n    if 'Modality' in train_df.columns:\n        print(\"📈 Modality distribution:\")\n        print(train_df['Modality'].value_counts())\n\n    # Create dataset\n    train_dataset = AneurysmDataset(train_df, config, mode='train')\n    print(f\"Created dataset with {len(train_dataset)} samples\")\n\n    # Initialize feature pipeline\n    print(\"🔧 Initializing enhanced feature extraction pipeline...\")\n    feature_pipeline = FeaturePipeline(config)\n    feature_pipeline.load_models()\n\n    # Extract features\n    print(\"🎯 Extracting features (this may take a while)...\")\n    X, y = feature_pipeline.extract_features(train_dataset)\n\n    if X.shape[0] == 0:\n        print(\"❌ No features extracted. Check data paths and format.\")\n        return\n\n    print(f\"✅ Extracted features: {X.shape}\")\n    print(f\"✅ Labels shape: {y.shape}\")\n\n    # Preprocess features\n    print(\"🔄 Preprocessing features...\")\n    X_scaled = feature_pipeline.scaler.fit_transform(X)\n\n    if X_scaled.shape[1] > 100:\n        X_selected = feature_pipeline.feature_selector.fit_transform(X_scaled, y[:, 0])\n    else:\n        X_selected = X_scaled\n\n    print(f\"✅ Final feature shape: {X_selected.shape}\")\n\n    # Train ensemble model\n    print(\"🤖 Training enhanced ensemble model...\")\n    ensemble = EnsembleModel(config)\n    ensemble.fit(X_selected, y)\n\n    # Cross-validation evaluation\n    print(\"📈 Evaluating model with cross-validation...\")\n    cv_scores = []\n\n    kf = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=config.SEED)\n\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X_selected, y[:, 0])):\n        print(f\"Evaluating fold {fold + 1}/{config.N_FOLDS}...\")\n\n        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n        y_train, y_val = y[train_idx], y[val_idx]\n\n        # Train fold model\n        fold_ensemble = EnsembleModel(config)\n        fold_ensemble.fit(X_train, y_train)\n\n        # Predict\n        y_pred = fold_ensemble.predict(X_val)\n\n        # Calculate score\n        score = calculate_competition_score(y_val, y_pred)\n        cv_scores.append(score)\n\n        print(f\"  Fold {fold + 1} Score: {score:.4f}\")\n\n    print(f\"🎊 Mean CV Score: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n\n    # Save model and pipeline\n    print(\"💾 Saving enhanced model pipeline...\")\n    model_artifacts = {\n        'ensemble': ensemble,\n        'scaler': feature_pipeline.scaler,\n        'selector': feature_pipeline.feature_selector,\n        'config': config,\n        'cv_scores': cv_scores,\n        'feature_names': list(range(X_selected.shape[1]))\n    }\n\n    with open('/kaggle/working/enhanced_aneurysm_ensemble.pkl', 'wb') as f:\n        pickle.dump(model_artifacts, f)\n\n    print(\"✅ Enhanced pipeline completed successfully!\")\n    print(f\"🏆 Final Performance: {np.mean(cv_scores):.4f} AUC-ROC\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T16:04:23.964393Z","iopub.execute_input":"2025-09-17T16:04:23.964906Z","iopub.status.idle":"2025-09-17T16:04:32.881716Z","shell.execute_reply.started":"2025-09-17T16:04:23.964875Z","shell.execute_reply":"2025-09-17T16:04:32.880132Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyradiomics in /usr/local/lib/python3.11/dist-packages (3.0.1)\nRequirement already satisfied: SimpleITK in /usr/local/lib/python3.11/dist-packages (2.5.2)\nRequirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.0.3)\nRequirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\nRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\nRequirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from pyradiomics) (1.26.4)\nRequirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pyradiomics) (1.8.0)\nRequirement already satisfied: pykwalify>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pyradiomics) (1.8.0)\nRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from pyradiomics) (1.17.0)\nRequirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\nRequirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (25.0)\nRequirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.14.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.33.1)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.9.2->pyradiomics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.9.2->pyradiomics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.9.2->pyradiomics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.9.2->pyradiomics) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.9.2->pyradiomics) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.9.2->pyradiomics) (2.4.1)\nRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from pykwalify>=1.6.0->pyradiomics) (0.6.2)\nRequirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from pykwalify>=1.6.0->pyradiomics) (2.9.0.post0)\nRequirement already satisfied: ruamel.yaml>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from pykwalify>=1.6.0->pyradiomics) (0.18.15)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.5.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.5)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.2.1)\nRequirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.16.0->pykwalify>=1.6.0->pyradiomics) (0.2.12)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.9.2->pyradiomics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.9.2->pyradiomics) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.9.2->pyradiomics) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.9.2->pyradiomics) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.6.15)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.9.2->pyradiomics) (2024.2.0)\n🔬 Starting Enhanced Multimodal Aneurysm Detection Pipeline...\n✨ Features: Modality-specific normalization, 3D U-Net, ViT, Advanced ensemble\n📊 Loading training data...\nLoaded 4348 training samples\n📈 Modality distribution:\nModality\nCTA           1808\nMRA           1252\nMRI T2         983\nMRI T1post     305\nName: count, dtype: int64\nCreated dataset with 4348 samples\n🔧 Initializing enhanced feature extraction pipeline...\n🎯 Extracting features (this may take a while)...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 clone.update(\n\u001b[0;32m--> 171\u001b[0;31m                     {\n\u001b[0m\u001b[1;32m    172\u001b[0m                         key: collate(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     {\n\u001b[0;32m--> 172\u001b[0;31m                         key: collate(\n\u001b[0m\u001b[1;32m    173\u001b[0m                             \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/2810683144.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_37/2810683144.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;31m# Extract features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🎯 Extracting features (this may take a while)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/2810683144.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;31m# The mapping type may not support `copy()` / `update(mapping)`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;31m# or `__init__(iterable)`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             return {\n\u001b[0m\u001b[1;32m    192\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;31m# or `__init__(iterable)`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             return {\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             }\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 ]\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"],"ename":"TypeError","evalue":"default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>","output_type":"error"}],"execution_count":27}]}